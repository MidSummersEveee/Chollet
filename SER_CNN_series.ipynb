{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SER_CNN_series.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM6hOWCV+Sca+YD9i9NX7P2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MidSummersEveee/Chollet/blob/master/SER_CNN_series.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "7EKZJ8kv7Vlo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive"
      ],
      "metadata": {
        "id": "ofZWYswc9Pzy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAd61PWI6zjd",
        "outputId": "6d1b61ef-2496-41c0-8763-4b95ce3f06da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies"
      ],
      "metadata": {
        "id": "xwTfbD8r9TAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 -q install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 torchtext==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryUkO1AG63x0",
        "outputId": "4b2bc38f-8ccd-46e9-92b4-1b1045a3db05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |█████████████                   | 834.1 MB 14.9 MB/s eta 0:01:22tcmalloc: large alloc 1147494400 bytes == 0x3a8ae000 @  0x7f412c5f9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████▌               | 1055.7 MB 1.2 MB/s eta 0:13:41tcmalloc: large alloc 1434370048 bytes == 0x7ef04000 @  0x7f412c5f9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████████           | 1336.2 MB 1.5 MB/s eta 0:07:44tcmalloc: large alloc 1792966656 bytes == 0x3d36000 @  0x7f412c5f9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.2 MB/s eta 0:04:47tcmalloc: large alloc 2241208320 bytes == 0x6eb1e000 @  0x7f412c5f9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 90.9 MB/s eta 0:00:01tcmalloc: large alloc 2041315328 bytes == 0xf4480000 @  0x7f412c5f81e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n",
            "tcmalloc: large alloc 2551644160 bytes == 0x1e23f8000 @  0x7f412c5f9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 8.6 kB/s \n",
            "\u001b[K     |████████████████████████████████| 20.6 MB 1.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 25.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchsummary==1.5.1"
      ],
      "metadata": {
        "id": "HRBCW3YiBTvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -qq install librosa\n",
        "!pip -qq install sklearn"
      ],
      "metadata": {
        "id": "OgkNb_oWXVxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torchsummary"
      ],
      "metadata": {
        "id": "aXBf1fBpVfPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0oJ0nJQ684v",
        "outputId": "845db328-e6a2-44f5-feab-12afe3a61af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.1+cu111\n",
            "11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.backends.cudnn.enabled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNKX82097BiX",
        "outputId": "e149faa2-215e-47b6-89a2-e7745dd0964e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sVBTM5Q6-cb",
        "outputId": "8a53fb52-c1c2-4f11-ca1b-58f13da09d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torchaudio"
      ],
      "metadata": {
        "id": "dEwX6ir5ekmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Device"
      ],
      "metadata": {
        "id": "Q5KGAt-n9Y0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = \"cuda\"\n",
        "else:\n",
        "  device = \"cpu\"\n",
        "print(f\"Using {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdoqhXcW9Iqp",
        "outputId": "4e5eb41b-7f58-4d36-e6ac-386a2fd00966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "O7slktvS7Q3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customization"
      ],
      "metadata": {
        "id": "9PC5pCyO8nR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "\n",
        "  def __init__(self,\n",
        "        annotations_file,\n",
        "        audio_dir,\n",
        "        transformation,\n",
        "        target_sample_rate,\n",
        "        num_samples,\n",
        "        device):\n",
        "    '''\n",
        "    Arguments:\n",
        "      annotations: path to csv file\n",
        "      audio_dir: path to audio dir\n",
        "      transformation: any audio tranform (Mel-spec, MFCC etc) provided by torch audio\n",
        "               (function pointer in fact, callable)\n",
        "      target_sample_rate: as named\n",
        "    '''\n",
        "    Dataset.__init__(self)\n",
        "    self.annotations = pd.read_csv(annotations_file)\n",
        "    print(self.annotations)\n",
        "    self.audio_dir = audio_dir\n",
        "    self.device = device\n",
        "    # print(self.device)\n",
        "    self.transformation = transformation.to(self.device)\n",
        "    self.target_sample_rate = target_sample_rate\n",
        "    self.num_samples = num_samples\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    '''\n",
        "    loading the waveform sample specified by the index\n",
        "    \n",
        "    Returns:\n",
        "      signal: <transformed> waveform\n",
        "      label: text in this case\n",
        "    '''\n",
        "    audio_sample_path = self._get_audio_sample_path(index)\n",
        "    label = self._get_audio_sample_label(index)\n",
        "\n",
        "    signal, sr = torchaudio.load(audio_sample_path)\n",
        "    signal = signal.to(self.device)\n",
        "    # signal = signal.cuda()\n",
        "    # Note: signal has shape (num_channels, num_samples) -> (2, 16000) -> (1, 16000)\n",
        "\n",
        "    signal = self._resample_if_necessary(signal, sr)  # resampling\n",
        "    signal = self._mix_down_if_necessary(signal)    # reduce to mono-channel (aggregate over 0st dim)\n",
        "    signal = self._cut_if_necessary(signal)\n",
        "    signal = self._right_pad_if_necessary(signal)   # right padding (when have less than expected)\n",
        "    signal = self.transformation(signal)       # apply tranformation\n",
        "\n",
        "    return signal, label\n",
        "\n",
        "  def _get_audio_sample_path(self, index):\n",
        "    '''\n",
        "    Join <dir name> & <.wav filename in df anno>\n",
        "    retrieve complete index-th audio sample url\n",
        "\n",
        "    Returns:\n",
        "      path: complete i-th audio sample url\n",
        "    '''\n",
        "\n",
        "    file_name = f'{self.annotations.iloc[index, 0]}.wav' # 0st col: 'UID'\n",
        "    path = os.path.join(self.audio_dir, file_name)\n",
        "    return path\n",
        "    \n",
        "  def _get_audio_sample_label(self, index):\n",
        "    # return self.annotations.iloc[index, 3] # 1st col: 'UTT' 4th: 'EMOTION'\n",
        "\n",
        "    label1 = self.annotations.iloc[index, 3]\n",
        "    label2 = torch.from_numpy(self.annotations.iloc[index, 4:7].to_numpy().astype(np.float32))\n",
        "\n",
        "    return {'label1': label1, 'label2': label2}\n",
        "\n",
        "  def _cut_if_necessary(self, signal):\n",
        "    if signal.shape[1] > self.num_samples:\n",
        "      signal = signal[:, :self.num_samples]\n",
        "    return signal\n",
        "\n",
        "  def _right_pad_if_necessary(self, signal):\n",
        "    length_signal = signal.shape[1]\n",
        "    if length_signal < self.num_samples:\n",
        "      num_missing_samples = self.num_samples - length_signal\n",
        "      last_dim_padding = (0, num_missing_samples) #(1, 2) 1 left 2 right\n",
        "      # [1, 1, 1] -> [0, 1, 1, 1, 0, 0]\n",
        "      signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
        "    return signal\n",
        "\n",
        "  def _resample_if_necessary(self, signal, sr):\n",
        "    if sr != self.target_sample_rate:\n",
        "      if self.device == \"cpu\":\n",
        "        resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
        "      elif self.device == 'cuda':\n",
        "        resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate).cuda()\n",
        "      else:\n",
        "        raise Exception(\"Device type error!\")\n",
        "      signal = resampler(signal)\n",
        "    return signal\n",
        "\n",
        "  def _mix_down_if_necessary(self, signal):\n",
        "    if signal.shape[0] > 1: # i.e. (2, 1000)\n",
        "      signal = torch.mean(signal, dim=0, keepdim=True)\n",
        "    return signal"
      ],
      "metadata": {
        "id": "_Bn0QIQJc3p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instantiation\n",
        "\n",
        "- Dataset\n",
        "- Data loader"
      ],
      "metadata": {
        "id": "Y1zoomhb8Sh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ANNOTATIONS_FILE = \"/content/drive/MyDrive/Dissertation/Datasets/cleaned_1.0/better_train_less.csv\"\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/Dissertation/Speech\"\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "# BATCH_SIZE = 32\n",
        "\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# SAMPLE_RATE = 16000\n",
        "# NUM_SAMPLES = 220500 * 3\n",
        "\n",
        "SAMPLE_RATE = 8000\n",
        "NUM_SAMPLES = 8000 * 2\n",
        "# NUM_SAMPLES = 16000 * 3"
      ],
      "metadata": {
        "id": "Ua2LdQVbduzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def create_data_loader(train_data, batch_size):\n",
        "  train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
        "  return train_dataloader\n",
        "\n",
        "# instantiating our dataset object and create data loader\n",
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "  sample_rate=SAMPLE_RATE,\n",
        "  n_fft=1024,\n",
        "  hop_length=512,\n",
        "  n_mels=64\n",
        ")\n",
        "\n",
        "iemocap = AudioDataset(\n",
        "      ANNOTATIONS_FILE,\n",
        "      AUDIO_DIR,\n",
        "      mel_spectrogram,\n",
        "      SAMPLE_RATE,\n",
        "      NUM_SAMPLES,\n",
        "      device\n",
        "      )\n",
        "\n",
        "train_dataloader = create_data_loader(iemocap, BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrA5C4mY8Tka",
        "outputId": "21241b7f-246b-4497-8a62-a233bed14e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         UID  \\\n",
            "0        Ses03M_impro04_M041   \n",
            "1        Ses01M_impro06_M011   \n",
            "2        Ses02M_impro08_M018   \n",
            "3        Ses03M_impro03_M011   \n",
            "4        Ses05F_impro03_F040   \n",
            "...                      ...   \n",
            "3125     Ses05M_impro01_F021   \n",
            "3126  Ses04F_script03_2_F030   \n",
            "3127     Ses05M_impro08_M024   \n",
            "3128  Ses03M_script01_2_M004   \n",
            "3129     Ses05F_impro06_F005   \n",
            "\n",
            "                                                    UTT EMOTIONS  EMOTION  \\\n",
            "0     Like, wow you're really smart we're going to g...        3        3   \n",
            "1     No, I mean it just came on really quick, you k...        2        2   \n",
            "2                                                 Okay.        0        0   \n",
            "3     Ah...Anyways, so she took the ring and she goe...        3        3   \n",
            "4                          There's still time for that.        3        3   \n",
            "...                                                 ...      ...      ...   \n",
            "3125  I'm gonna- I'm gonna bring security over and h...        1        1   \n",
            "3126                                               Why?        1        1   \n",
            "3127   Absolutely.  It's a new service we are offering.        0        0   \n",
            "3128               Who said he even thought about that?        0        0   \n",
            "3129                                           Kind of.        2        2   \n",
            "\n",
            "             V         A         D  neu  ang  sad  hap  neu_m  ang_m  sad_m  \\\n",
            "0     0.777778  0.625000  0.333333    0    0    0    1      0      0      0   \n",
            "1     0.222222  0.375000  0.555556    0    0    1    0      0      0      1   \n",
            "2     0.444444  0.333325  0.407400    1    0    0    0      1      0      0   \n",
            "3     0.666667  0.750000  0.777778    0    0    0    1      0      0      0   \n",
            "4     0.666667  0.625000  0.555556    0    0    0    1      0      0      0   \n",
            "...        ...       ...       ...  ...  ...  ...  ...    ...    ...    ...   \n",
            "3125  0.111111  0.750000  0.888889    0    1    0    0      0      1      0   \n",
            "3126  0.333333  0.375000  0.555556    0    1    0    0      0      1      0   \n",
            "3127  0.555556  0.625000  0.555556    1    0    0    0      1      0      0   \n",
            "3128  0.333333  0.500000  0.555556    1    0    0    0      1      0      0   \n",
            "3129  0.111111  0.375000  0.444444    0    0    1    0      0      0      1   \n",
            "\n",
            "      hap_m  \n",
            "0         1  \n",
            "1         0  \n",
            "2         0  \n",
            "3         1  \n",
            "4         1  \n",
            "...     ...  \n",
            "3125      0  \n",
            "3126      0  \n",
            "3127      0  \n",
            "3128      0  \n",
            "3129      0  \n",
            "\n",
            "[3130 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import IPython.display as ipd\n",
        "\n",
        "# print(f'<{len(iemocap)}> samples confirmed in the dataset.')\n",
        "\n",
        "# print(iemocap[1])\n",
        "\n",
        "# sample_signal, sample_label = iemocap[1]\n",
        "\n",
        "# print(f'Sample Audio: {sample_signal.shape}')\n",
        "# print(f'Sample Label: {sample_label}')\n",
        "\n",
        "\n",
        "# # ipd.Audio(data=np.asarray(iemocap[1][0]), autoplay=True, rate=16000)\n",
        "# ipd.Audio(data=np.asarray(sample_signal), autoplay=True, rate=16000)"
      ],
      "metadata": {
        "id": "DfjjZ5bEdxy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Split"
      ],
      "metadata": {
        "id": "3LBd_4IucbRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(40).reshape(1,1,5,8)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEDOliYEcaxK",
        "outputId": "0e78c294-37b4-4cbd-c5c6-fdbf0878f883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
              "          [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
              "          [16, 17, 18, 19, 20, 21, 22, 23],\n",
              "          [24, 25, 26, 27, 28, 29, 30, 31],\n",
              "          [32, 33, 34, 35, 36, 37, 38, 39]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsxxLeqXeWAQ",
        "outputId": "911b48ac-998b-4a6b-953b-76100f25ba59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def slicing(tensor, r=4):\n",
        "  len_time = a.shape[-1]\n",
        "  assert len_time % r == 0, f'not dividable by r of {r}'\n",
        "  len_small = len_time // r\n",
        "  return [\n",
        "      a[:,:,:, i:i+2] for i in range(0, len_time, len_small)\n",
        "  ]"
      ],
      "metadata": {
        "id": "07ChRpCieQrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "slicing(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvM6YWCchHCI",
        "outputId": "06e6a478-425f-4c94-aca0-c8f3bb2ada6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[[[ 0,  1],\n",
              "           [ 8,  9],\n",
              "           [16, 17],\n",
              "           [24, 25],\n",
              "           [32, 33]]]]), tensor([[[[ 2,  3],\n",
              "           [10, 11],\n",
              "           [18, 19],\n",
              "           [26, 27],\n",
              "           [34, 35]]]]), tensor([[[[ 4,  5],\n",
              "           [12, 13],\n",
              "           [20, 21],\n",
              "           [28, 29],\n",
              "           [36, 37]]]]), tensor([[[[ 6,  7],\n",
              "           [14, 15],\n",
              "           [22, 23],\n",
              "           [30, 31],\n",
              "           [38, 39]]]])]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(slicing(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUqkXl4fgKu7",
        "outputId": "90227827-63e7-40a2-ed6d-c5846a0b9542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat(slicing(a), -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1sD8hgbeCC7",
        "outputId": "66000fe0-f24c-4055-b773-59ecaf4b6213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
              "          [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
              "          [16, 17, 18, 19, 20, 21, 22, 23],\n",
              "          [24, 25, 26, 27, 28, 29, 30, 31],\n",
              "          [32, 33, 34, 35, 36, 37, 38, 39]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture"
      ],
      "metadata": {
        "id": "YBScDngq7fYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "gqZP3cml7Qeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `__init__()`: the constructor defining layer structure of the network.\n",
        "\n",
        "- `forward()`: instruct pytorch how to pass the information/data from one layer to next."
      ],
      "metadata": {
        "id": "C0hq8zuh74SM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "iLj1GkIMxNMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNNetwork(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # sequential convolutions  / flatten / linear / softmax\n",
        "    self.convSeq = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=16,  # 16 filters\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=2\n",
        "        ),\n",
        "        nn.Tanh(),\n",
        "        # nn.Dropout2d(0.1),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        nn.Conv2d(\n",
        "            in_channels=16,\n",
        "            out_channels=32,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=2\n",
        "        ),\n",
        "        nn.Tanh(),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        nn.Conv2d(\n",
        "            in_channels=32,\n",
        "            out_channels=64,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=2\n",
        "        ),\n",
        "        nn.Tanh(),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        nn.Conv2d(\n",
        "            in_channels=64,\n",
        "            out_channels=128,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=2\n",
        "        ),\n",
        "        nn.Tanh(),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        nn.Flatten()\n",
        "\n",
        "    )\n",
        "\n",
        "    # flatten\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "    # linear/dense\n",
        "    # self.linear = nn.Linear(128 * 5 * 4, 4)\n",
        "    self.linear1 = nn.Sequential(\n",
        "        # nn.Linear(128 * 1 * 8, 800),\n",
        "        nn.Linear(64 * 5 * 4, 400),\n",
        "        nn.Tanh(),\n",
        "        # nn.Linear(54000, 4000),\n",
        "        # nn.Tanh(),\n",
        "        # nn.BatchNorm1d(1024),\n",
        "        nn.Linear(400, 4)\n",
        "    )\n",
        "\n",
        "    # VAD\n",
        "    self.linear2 = nn.Sequential(\n",
        "        nn.Linear(64 * 5 * 4, 512),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(512, 300),\n",
        "        nn.Tanh(),\n",
        "        # nn.BatchNorm1d(1024),\n",
        "        nn.Linear(300, 3)\n",
        "    )\n",
        "\n",
        "    # softmax\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "  \n",
        "  # how to pass data through layers\n",
        "  def forward(self, input_data):\n",
        "\n",
        "    # sliced = slicing(input_data)\n",
        "    # sliced.to(device)\n",
        "    # feed = []\n",
        "    # for s in sliced:\n",
        "    #   s = self.conv1(s)\n",
        "    #   s = self.conv2(s)\n",
        "    #   s = self.conv3(s)\n",
        "    #   s = self.conv4(s)\n",
        "    #   s = self.flatten(s)\n",
        "    #   feed.append(s)\n",
        "\n",
        "    one = input_data[:,:,:, 0:input_data.shape[-1] // 4]\n",
        "    two = input_data[:,:,:, input_data.shape[-1] // 4: input_data.shape[-1] // 4 * 2]\n",
        "    thr = input_data[:,:,:, input_data.shape[-1] // 4 * 2:input_data.shape[-1] // 4 * 3]\n",
        "    fou = input_data[:,:,:, input_data.shape[-1] // 4 * 3:input_data.shape[-1] // 4 * 4]\n",
        "\n",
        "    one = self.convSeq(one)\n",
        "    two = self.convSeq(two)\n",
        "    thr = self.convSeq(thr)\n",
        "    fou = self.convSeq(fou)\n",
        "\n",
        "    # x = torch.cat((one,two,thr,fou), -1)\n",
        "    # x = torch.cat((one,two,thr,fou), 0)\n",
        "\n",
        "    x = torch.add(one, two)\n",
        "    x = torch.add(x, thr)\n",
        "    x = torch.add(x, fou)\n",
        "    # x = one+two+thr+fou\n",
        "    x = x * 0.25\n",
        "\n",
        "    # x = F.pad(x, pad=(0, 0, 0, 1920 - x.shape[0]))\n",
        "    # print(x.shape)\n",
        "    x.to(device)\n",
        "\n",
        "    x1 = self.linear1(x)\n",
        "    x2 = self.linear2(x)\n",
        "\n",
        "    x1 = self.softmax(x1)\n",
        "    return x1, x2"
      ],
      "metadata": {
        "id": "aFbqKRL17cxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cnn_sample = CNNNetwork()\n",
        "# summary(\n",
        "#     cnn.cuda(),  # model\n",
        "    \n",
        "#      # shape of the spetrogram\n",
        "#     (\n",
        "#         1,  # number of channels\n",
        "#         64,  # number of mel-banks\n",
        "#         44  # time axis\n",
        "#     )\n",
        "#     )"
      ],
      "metadata": {
        "id": "33T-KGv4BldX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "J6prNqqsawNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train & Save"
      ],
      "metadata": {
        "id": "N4s2bRL41OAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "# BATCH_SIZE = 128\n",
        "# EPOCHS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# SAMPLE_RATE = 16000\n",
        "# NUM_SAMPLES = 22050\n",
        "\n",
        "\n",
        "def train_single_epoch(model, data_loader, loss_fn, optimiser, device, i):\n",
        "  for input, target in data_loader:\n",
        "    input, target1, target2 = input.to(device), target['label1'].to(device), target['label2'].to(device)\n",
        "\n",
        "    # calculate loss\n",
        "    out1, out2 = model(input)\n",
        "    loss1 = loss_fn(out1, target1)\n",
        "    loss2 = nn.L1Loss()(out2, target2)\n",
        "\n",
        "    # backpropagate error and update weights\n",
        "    loss = loss1 + loss2\n",
        "    # writer.add_scalar(\"Loss/train\", loss, i)\n",
        "    optimiser.zero_grad()\n",
        "    \n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "  print(f\"loss: {loss.item()}\")\n",
        "\n",
        "\n",
        "def train(model, data_loader, loss_fn, optimiser, device, epochs):\n",
        "  for i in range(epochs):\n",
        "      print(f\"Epoch {i+1}\")\n",
        "      train_single_epoch(model, data_loader, loss_fn, optimiser, device, i)\n",
        "      print(\"---------------------------\")\n",
        "  print(\"Finished training\")"
      ],
      "metadata": {
        "id": "PJRrx_LPawUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss & Optimizer"
      ],
      "metadata": {
        "id": "meYOtBswN71g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construct model and assign it to device\n",
        "cnn = CNNNetwork().to(device)\n",
        "print(cnn)\n",
        "\n",
        "# initialise loss funtion + optimiser\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.Adam(\n",
        "                cnn.parameters(),\n",
        "                lr=LEARNING_RATE\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8IuuoeEbxGL",
        "outputId": "015362b6-8a4c-46a4-81d8-f90095523e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNNNetwork(\n",
            "  (convSeq): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (1): Tanh()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (4): Tanh()\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (7): Tanh()\n",
            "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (10): Tanh()\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear1): Sequential(\n",
            "    (0): Linear(in_features=1280, out_features=400, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=400, out_features=4, bias=True)\n",
            "  )\n",
            "  (linear2): Sequential(\n",
            "    (0): Linear(in_features=1280, out_features=512, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=512, out_features=300, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=300, out_features=3, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "train(cnn, train_dataloader, loss_fn, optimiser, device, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqJ0JdbNN31s",
        "outputId": "4472d2c0-9551-4081-c421-c0a441ec7423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "loss: 1.3363276720046997\n",
            "---------------------------\n",
            "Epoch 2\n",
            "loss: 1.3249537944793701\n",
            "---------------------------\n",
            "Epoch 3\n",
            "loss: 1.289804220199585\n",
            "---------------------------\n",
            "Epoch 4\n",
            "loss: 1.2833184003829956\n",
            "---------------------------\n",
            "Epoch 5\n",
            "loss: 1.28504478931427\n",
            "---------------------------\n",
            "Epoch 6\n",
            "loss: 1.2310537099838257\n",
            "---------------------------\n",
            "Epoch 7\n",
            "loss: 1.1915401220321655\n",
            "---------------------------\n",
            "Epoch 8\n",
            "loss: 1.1909608840942383\n",
            "---------------------------\n",
            "Epoch 9\n",
            "loss: 1.1275132894515991\n",
            "---------------------------\n",
            "Epoch 10\n",
            "loss: 1.0954763889312744\n",
            "---------------------------\n",
            "Finished training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# writer.flush()\n",
        "# writer.close()"
      ],
      "metadata": {
        "id": "gr2o7xw4yPGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !kill 2108"
      ],
      "metadata": {
        "id": "L4LusTiH4dk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tensorboard --logdir = content/logsdir\n",
        "# %tensorboard --logdir content/drive/MyDrive/Dissertation/Models/logsdirs/logsdir1/"
      ],
      "metadata": {
        "id": "LsEdZ10gu_nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving"
      ],
      "metadata": {
        "id": "q21AVsvFOCfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"/content/drive/MyDrive/Dissertation/Models/SER/clean_1.0/CNN_series.pth\""
      ],
      "metadata": {
        "id": "MQL5ehKwyjht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "torch.save(cnn.state_dict(), output_path)\n",
        "print(f\"Trained feed forward net saved at [{output_path}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGlEYj9pN2Xm",
        "outputId": "6d9c7f7a-e230-4261-e0cc-040f4aa0a233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained feed forward net saved at [/content/drive/MyDrive/Dissertation/Models/SER/clean_1.0/CNN_series.pth]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "PGfNH9cbo76e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class Mapping"
      ],
      "metadata": {
        "id": "5Uo9zM6po_ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_mapping = ['neu','ang','sad','hap']\n",
        "INDICE = [0, 1, 2, 3]\n",
        "\n",
        "EMO_2_ID = dict(zip(class_mapping, INDICE))\n",
        "ID_2_EMO = dict(zip(INDICE, class_mapping))"
      ],
      "metadata": {
        "id": "e_-uRBYHo2wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions"
      ],
      "metadata": {
        "id": "TTa0Wt8spp-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, input, target, class_mapping):\n",
        "  model.eval()\n",
        "\n",
        "  # no need for gradient during inference\n",
        "  with torch.no_grad():\n",
        "    # predictions, vad = model(input)\n",
        "    predictions, vads = model(input)\n",
        "    # tensor (1, 4) -> [[0,1, 0.2, 0.6, 0.1]]\n",
        "\n",
        "    predicted_index = predictions[0].argmax(0)\n",
        "    # print(predicted_index)\n",
        "\n",
        "    predicted = class_mapping[predicted_index]\n",
        "    expected = class_mapping[target]\n",
        "  return predicted, expected"
      ],
      "metadata": {
        "id": "CYfTUhd9poMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load back"
      ],
      "metadata": {
        "id": "xLAsaaiFqQCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_trained = CNNNetwork()\n",
        "state_dict = torch.load(output_path)\n",
        "cnn_trained.load_state_dict(state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TZikDRPqQUZ",
        "outputId": "c69cf919-9c53-4141-bb0a-54e941f14607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ANNOTATIONS_FILE = \"/content/drive/MyDrive/Dissertation/Datasets/cleaned_1.0/better_valid_less.csv\"\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/Dissertation/Speech\"\n",
        "\n",
        "# instantiating our dataset object and create data loader\n",
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "  sample_rate=SAMPLE_RATE,\n",
        "  n_fft=1024,\n",
        "  hop_length=512,\n",
        "  n_mels=64\n",
        ")\n",
        "\n",
        "iemocap_valid = AudioDataset(\n",
        "      ANNOTATIONS_FILE,\n",
        "      AUDIO_DIR,\n",
        "      mel_spectrogram,\n",
        "      SAMPLE_RATE,\n",
        "      NUM_SAMPLES,\n",
        "      'cpu'\n",
        "      # device\n",
        "      )\n",
        "\n",
        "# valid_dataloader = create_data_loader(iemocap_valid, BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrMYbAh1rEWF",
        "outputId": "1543acbb-baaf-472d-912a-bb6fc15d1a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         UID  \\\n",
            "0        Ses04F_impro08_F008   \n",
            "1        Ses03M_impro03_F022   \n",
            "2     Ses02F_script02_1_M031   \n",
            "3        Ses05F_impro03_F033   \n",
            "4     Ses02F_script02_2_F005   \n",
            "...                      ...   \n",
            "1039  Ses02F_script01_1_F018   \n",
            "1040     Ses01F_impro07_F013   \n",
            "1041     Ses05M_impro03_M018   \n",
            "1042     Ses03M_impro03_M018   \n",
            "1043     Ses03M_impro02_M031   \n",
            "\n",
            "                                                    UTT EMOTIONS  EMOTION  \\\n",
            "0     Well I'm very sorry, sir.  They should have de...        0        0   \n",
            "1                              Oh that's kind of sweet.      0,3        3   \n",
            "2     I don't get it.  The first time we came here, ...        0        0   \n",
            "3                                  Yeah, she loves him.        3        3   \n",
            "4     God damn it, Augie, don't ask me that.  I hate...        1        1   \n",
            "...                                                 ...      ...      ...   \n",
            "1039            Well, that's only your business, Chris.        0        0   \n",
            "1040          I would be like- Oh. Right, right, right.        3        3   \n",
            "1041  Um- And she wants you to be in it, too.  She l...        3        3   \n",
            "1042  dim down the lights and uh, I got on one of th...      0,3        3   \n",
            "1043                                  What do you mean?        2        2   \n",
            "\n",
            "             V         A         D  neu  ang  sad  hap  neu_m  ang_m  sad_m  \\\n",
            "0     0.666667  0.375000  0.444444    1    0    0    0      1      0      0   \n",
            "1     0.555556  0.250000  0.444444    0    0    0    1      1      0      0   \n",
            "2     0.333333  0.750000  0.777778    1    0    0    0      1      0      0   \n",
            "3     0.666667  0.500000  0.777778    0    0    0    1      0      0      0   \n",
            "4     0.111111  0.875000  0.888889    0    1    0    0      0      1      0   \n",
            "...        ...       ...       ...  ...  ...  ...  ...    ...    ...    ...   \n",
            "1039  0.333333  0.500000  0.666667    1    0    0    0      1      0      0   \n",
            "1040  0.777778  0.750000  0.777778    0    0    0    1      0      0      0   \n",
            "1041  0.666667  0.583325  0.481489    0    0    0    1      0      0      0   \n",
            "1042  0.666667  0.500000  0.777778    0    0    0    1      1      0      0   \n",
            "1043  0.222222  0.375000  0.444444    0    0    1    0      0      0      1   \n",
            "\n",
            "      hap_m  \n",
            "0         0  \n",
            "1         1  \n",
            "2         0  \n",
            "3         1  \n",
            "4         0  \n",
            "...     ...  \n",
            "1039      0  \n",
            "1040      1  \n",
            "1041      1  \n",
            "1042      1  \n",
            "1043      0  \n",
            "\n",
            "[1044 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "P_bW4iaQt_f6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [batch_size, num_channels, freq, time]\n",
        "input, target1, target2 = iemocap_valid[0][0], iemocap_valid[0][1]['label1'], iemocap_valid[0][1]['label2']\n",
        "\n",
        "# 0 is the index of insertion\n",
        "input.unsqueeze_(0)\n",
        "\n",
        "print(target1)\n",
        "\n",
        "# input, target1 = input.cuda(), torch.tensor(target1).cuda()\n",
        "\n",
        "predicted, expected = predict(cnn_trained, input, target1, class_mapping)\n",
        "\n",
        "print(f'Predicted: {predicted}, expected: {expected}')\n",
        "print(input.shape)\n",
        "print(len(iemocap_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOCbhJ3-scWI",
        "outputId": "9aba7218-f482-41cf-91ef-0c96ab014b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Predicted: neu, expected: neu\n",
            "torch.Size([1, 1, 64, 32])\n",
            "1044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def results(dataset, model):\n",
        "  predictions = []\n",
        "  expectations = []\n",
        "\n",
        "  size = len(dataset)\n",
        "  for i in range(size):\n",
        "    X, Y = dataset[i][0], dataset[i][1]['label1']\n",
        "    X.unsqueeze_(0)\n",
        "    # X = X.cuda()\n",
        "    # Y = torch.from_numpy(Y)\n",
        "    # Y = Y.cuda()\n",
        "    predicted, expected = predict(model, X, Y, class_mapping)\n",
        "    predictions.append(predicted)\n",
        "    expectations.append(expected)\n",
        "\n",
        "  return expectations, predictions\n",
        "\n",
        "y_true, y_predict = results(iemocap_valid, cnn_trained)"
      ],
      "metadata": {
        "id": "ma8ENIYy1w16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GM81I5N5yOu",
        "outputId": "172c7169-d0b2-4e67-d861-97d479bc2f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1044"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ID_2_EMO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hsn3kZA8Bzq",
        "outputId": "3ee67eef-afcd-4340-9ff6-6ebf48002d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'neu', 1: 'ang', 2: 'sad', 3: 'hap'}"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = [EMO_2_ID[y] for y in y_true]\n",
        "y_predict = [EMO_2_ID[y] for y in y_predict]"
      ],
      "metadata": {
        "id": "KM7hV-Um6166"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "c = classification_report(y_true, y_predict, target_names=class_mapping, zero_division=1)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZKg_SWu9iO6",
        "outputId": "ddeb0b3e-ed54-432e-8b8c-d0e8ce225c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neu       0.43      0.64      0.51       320\n",
            "         ang       0.55      0.54      0.55       217\n",
            "         sad       0.55      0.50      0.52       221\n",
            "         hap       0.47      0.24      0.32       286\n",
            "\n",
            "    accuracy                           0.48      1044\n",
            "   macro avg       0.50      0.48      0.48      1044\n",
            "weighted avg       0.49      0.48      0.47      1044\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(ANNOTATIONS_FILE)\n",
        "names = df.columns.to_list()\n",
        "names[-4:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHij8GHBhzpf",
        "outputId": "88405f62-6928-47ad-d07e-84005ec6d211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neu_m', 'ang_m', 'sad_m', 'hap_m']"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_multi = df[['neu_m', 'ang_m', 'sad_m', 'hap_m']].to_numpy()\n",
        "y_true_multi.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF8ucfJSlKIG",
        "outputId": "ce9ae042-457a-4c43-d451-de6077b4ea38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1044, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_multi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTNBJqCZmE1x",
        "outputId": "978ad509-ddd0-475c-8ee8-7ab389eac4a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0],\n",
              "       [1, 0, 0, 1],\n",
              "       [1, 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, 1],\n",
              "       [1, 0, 0, 1],\n",
              "       [0, 0, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN64OiF4mIxY",
        "outputId": "22c88bbf-b41e-4d33-8cbe-8d9413fe374c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 2, 0, 0, 1, 2, 0, 2, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # y_predict_hot = pd.get_dummies(y_predict)\n",
        "y_predict = np.array(y_predict)\n",
        "# y_predict_hot = np.zeros(y_predict.size, y_predict.max() + 1)\n",
        "# y_predict_hot[np.arange(y_predict.size), y_predict] = 1\n",
        "# y_predict_hot"
      ],
      "metadata": {
        "id": "p2M-wZBwm7Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_predict"
      ],
      "metadata": {
        "id": "zVxEo1jUpXBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(n, class_num, col_wise=True):\n",
        "  a = np.eye(class_num)[n.reshape(-1)]\n",
        "  return a.T if col_wise else a"
      ],
      "metadata": {
        "id": "pW3X1BxopapI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_hot = one_hot(y_predict, 4, False)\n",
        "y_predict_hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAMeC8bhpeap",
        "outputId": "958cf483-780d-4f6a-ffe6-5554c5d81f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c2 = classification_report(y_true_multi, y_predict_hot, target_names=class_mapping, zero_division=1)\n",
        "print(c2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7aZXnOdpxte",
        "outputId": "59f0c733-530c-4050-d0ae-efbd98363d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neu       0.56      0.59      0.58       458\n",
            "         ang       0.57      0.50      0.53       242\n",
            "         sad       0.61      0.47      0.53       259\n",
            "         hap       0.49      0.24      0.33       294\n",
            "\n",
            "   micro avg       0.56      0.47      0.51      1253\n",
            "   macro avg       0.56      0.45      0.49      1253\n",
            "weighted avg       0.56      0.47      0.50      1253\n",
            " samples avg       0.56      0.48      0.51      1253\n",
            "\n"
          ]
        }
      ]
    }
  ]
}